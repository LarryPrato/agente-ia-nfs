# AI Agents para AnÃ¡lise de Notas Fiscais

Este projeto implementa um sistema de ETL (Extract, Transform, Load) e um agente de IA para consultar dados de notas fiscais em linguagem natural. Ele suporta tanto modelos de LLM em nuvem (HuggingFace) quanto modelos locais (GGUF via LlamaCpp).

## ğŸš€ Funcionalidades

* **ETL Automatizado**: Extrai dados de arquivos ZIP (cabeÃ§alho e itens), transforma-os e os carrega em um banco de dados SQLite.
* **Agente de IA**: Permite consultas em linguagem natural sobre os dados das notas fiscais, utilizando um LLM e LangChain SQL Agent.
* **Ambiente HÃ­brido**: Suporte para LLMs em nuvem (ex: Flan-T5, Mistral) e LLMs locais (modelos GGUF).
* **Interface Web**: AplicaÃ§Ã£o Streamlit para upload de arquivos e interaÃ§Ã£o com o agente de IA.
* **API REST**: Endpoint FastAPI para integraÃ§Ã£o programÃ¡tica.

## ğŸ“¦ Estrutura do Projeto

notas_fiscais/
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ run.py
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ init.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ extract.py
â”‚   â”œâ”€â”€ transform.py
â”‚   â”œâ”€â”€ database.py
â”‚   â”œâ”€â”€ query.py
â”‚   â”œâ”€â”€ run_etl.py
â”‚   â””â”€â”€ api.py
â”‚
â”œâ”€â”€ interface/
â”‚   â””â”€â”€ streamlit_app.py
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/
â”‚   â”œâ”€â”€ temp/
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ notas.db
â”‚
â””â”€â”€ tests/
â”œâ”€â”€ init.py
â”œâ”€â”€ conftest.py
â”œâ”€â”€ test_extract.py
â”œâ”€â”€ test_transform.py
â”œâ”€â”€ test_database.py
â””â”€â”€ test_query.py

## âš™ï¸ ConfiguraÃ§Ã£o e InstalaÃ§Ã£o

1.  **Clone o RepositÃ³rio:**
    ```bash
    git clone [https://github.com/seu-usuario/ai_agents_notas_fiscais.git](https://github.com/seu-usuario/ai_agents_notas_fiscais.git)
    cd ai_agents_notas_fiscais
    ```

2.  **VariÃ¡veis de Ambiente:**
    Crie um arquivo `.env` na raiz do projeto, copiando e configurando o `.env.example`:
    ```bash
    cp .env.example .env
    # Edite .env com suas preferÃªncias (ENV=local/cloud, LLM_CLOUD_MODEL_NAME, LLM_LOCAL_MODEL_PATH, etc.)
    ```

3.  **ConfiguraÃ§Ã£o Inicial (Host ou Docker):**

    * **OpÃ§Ã£o A: Rodar Diretamente no Host (Recomendado para Desenvolvimento):**
        ```bash
        python -m venv venv
        source venv/bin/activate # ou `.\venv\Scripts\activate` no Windows
        pip install -r requirements.txt
        python setup.py # Cria diretÃ³rios, etc.
        # Se ENV=local, vocÃª precisarÃ¡ baixar o modelo GGUF manualmente ou usar `make download-model`
        ```

    * **OpÃ§Ã£o B: Rodar com Docker (Recomendado para ProduÃ§Ã£o/ImplantaÃ§Ã£o):**
        Certifique-se de ter Docker e Docker Compose instalados.
        ```bash
        docker-compose up --build -d
        ```

4.  **Baixar Modelo Local (se `ENV=local` no `.env`):**
    ```bash
    make download-model
    ```
    (Este comando usarÃ¡ a URL padrÃ£o ou a configurada no `Makefile` para baixar o modelo GGUF para `models/`).

## ğŸš€ Como Usar

### 1. Via Interface Web (Streamlit)

ApÃ³s iniciar com Docker Compose (`docker-compose up -d`) ou localmente:
bash
# Se localmente
`streamlit run interface/streamlit_app.py`

Acesse http://localhost:8501 no seu navegador.

Upload: Use a seÃ§Ã£o "Upload e Processamento de Dados" para enviar um arquivo ZIP.
Consulta: Use a seÃ§Ã£o "Consulte Seus Dados" para fazer perguntas em linguagem natural.

### 2. Via API (FastAPI)
ApÃ³s iniciar com Docker Compose (docker-compose up -d) ou localmente:

# Se localmente
`python run.py start_api`

Acesse http://localhost:8000/docs para a documentaÃ§Ã£o interativa da API (Swagger UI).

/upload-and-process/ (POST): Para enviar arquivos ZIP.
/query/ (GET): Para enviar perguntas.


### 3. Via Linha de Comando (CLI)
Use o script run.py para interagir diretamente com o sistema.

Executar ETL para um arquivo ZIP:
`python run.py etl data/input/seuarquivo.zip`
# Ou via Makefile (se o arquivo estiver em data/input/)
`make run_etl FILE=seuarquivo.zip`

Fazer uma consulta:

Bash

`python run.py query "Qual o fornecedor com o maior valor total de notas?"`
# Ou via Makefile
`make run_query QUERY="Qual o fornecedor com o maior valor total de notas?"`
Iniciar a API:

Bash

`python run.py start_api`
Iniciar o Streamlit:

Bash

`python run.py start_streamlit`
ğŸ§ª Testes
Bash

pytest
(Para rodar todos os testes automatizados.)

ğŸ§¹ Limpeza
Para remover arquivos gerados (banco de dados, temporÃ¡rios, logs):

Bash

`make clean`