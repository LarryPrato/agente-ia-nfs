{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q fastapi uvicorn python-multipart aiofiles pyngrok langchain langchain_community langchain-google-genai nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pyngrok import ngrok\n",
    "ngrok.set_auth_token(\"*********************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ‚úÖ Imports principais\n",
    "# =====================================\n",
    "import shutil\n",
    "import sqlite3\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import pandas as pd\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "import threading\n",
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "import ast\n",
    "import re\n",
    "\n",
    "from langchain.agents import create_sql_agent, Tool, initialize_agent, AgentType\n",
    "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ‚úÖ Configura o logger do Uvicorn e outros\n",
    "# =====================================\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(\"uvicorn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ‚úÖ Inicializar modelo Gemini-flash\n",
    "# =====================================\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"models/gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    google_api_key=secret_value_0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ‚úÖ Diret√≥rios e banco de dados\n",
    "# =====================================\n",
    "DATA_DIR = Path(\"/tmp/data\")\n",
    "INPUT_DIR = DATA_DIR / \"input\"\n",
    "TEMP_DIR = DATA_DIR / \"temp\"\n",
    "DB_PATH = DATA_DIR / \"notas.db\"\n",
    "\n",
    "for d in [INPUT_DIR, TEMP_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ‚úÖ ETL do arquivo ZIP para SQLite\n",
    "# =====================================\n",
    "def run_etl_pipeline(zip_path: Path) -> bool:\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(TEMP_DIR)\n",
    "\n",
    "        csv_files = list(TEMP_DIR.glob(\"*.csv\"))\n",
    "        cabecalho_file = [f for f in csv_files if \"cabecalho\" in f.name.lower()]\n",
    "        itens_file = [f for f in csv_files if \"itens\" in f.name.lower()]\n",
    "\n",
    "        if not cabecalho_file or not itens_file:\n",
    "            cabecalho_file, itens_file = csv_files[:2]\n",
    "\n",
    "        cab = pd.read_csv(cabecalho_file[0])\n",
    "        itens = pd.read_csv(itens_file[0])\n",
    "\n",
    "        cab.columns = cab.columns.str.lower().str.replace(\" \", \"_\").str.replace(\"/\", \"_\")\n",
    "        itens.columns = itens.columns.str.lower().str.replace(\" \", \"_\").str.replace(\"/\", \"_\")\n",
    "\n",
    "        chave = next(\n",
    "            (k for k in [\"chave\", \"chave_de_acesso\", \"numero_nf\", \"id_nota\", \"id\"]\n",
    "             if k in cab.columns and k in itens.columns), None)\n",
    "\n",
    "        if not chave:\n",
    "            print(\"‚ùå Nenhuma chave comum.\")\n",
    "            return False\n",
    "\n",
    "        merged = pd.merge(cab, itens, on=chave, how=\"left\")\n",
    "        merged[\"processed_at\"] = pd.Timestamp.now().isoformat()\n",
    "\n",
    "        conn = sqlite3.connect(DB_PATH)\n",
    "        merged.to_sql(\"notas_fiscais\", conn, if_exists=\"replace\", index=False)\n",
    "        conn.close()\n",
    "\n",
    "        shutil.rmtree(TEMP_DIR)\n",
    "        TEMP_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Erro no ETL:\", e)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ‚úÖ App FastAPI\n",
    "# =====================================\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "def root():\n",
    "    logger.info(\"‚úÖ Rota / acessada com sucesso\")\n",
    "    return {\"mensagem\": \"API rodando com sucesso\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ‚úÖ Endpoint: Upload ZIP\n",
    "# =====================================\n",
    "@app.post(\"/upload/\")\n",
    "async def upload(file: UploadFile = File(...)):\n",
    "    logger.info(f\"üìÅ Arquivo recebido: {file.filename}\")\n",
    "    zip_path = INPUT_DIR / file.filename\n",
    "    with open(zip_path, \"wb\") as f:\n",
    "        f.write(await file.read())\n",
    "\n",
    "    if run_etl_pipeline(zip_path):\n",
    "        return {\"status\": \"ok\", \"message\": \"Arquivo processado com sucesso!\"}\n",
    "    return {\"status\": \"erro\", \"message\": \"Falha ao processar ZIP.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ‚úÖ Endpoint: Consultar agente com prompt rico, SQLDatabaseToolkit, e resposta formatada\n",
    "# =====================================\n",
    "@app.get(\"/query/\")\n",
    "async def query(question: str):\n",
    "    try:\n",
    "        logger.info(f\"üß† Pergunta recebida: {question}\")\n",
    "\n",
    "        # Conectar ao banco\n",
    "        db = SQLDatabase.from_uri(f\"sqlite:///{DB_PATH}\")\n",
    "        toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "        tools = toolkit.get_tools()\n",
    "\n",
    "        prefix = f\"\"\"\n",
    "          Voc√™ √© um analista especializado em dados fiscais do Brasil.\n",
    "          Use como fonte √∫nica a tabela `notas_fiscais`, cujo schema √©:\n",
    "          {db.get_table_info()}\n",
    "\n",
    "          **Regras importantes**:\n",
    "          1. Para perguntas sobre montantes por dia, use sempre `substr(data_emiss√£o_x, 1, 10)` para extrair apenas a data (YYYY-MM-DD).\n",
    "             Exemplo:\n",
    "             ```sql\n",
    "             SELECT substr(data_emiss√£o_x, 1, 10) AS data, SUM(valor_nota_fiscal) AS total_vendas\n",
    "             FROM notas_fiscais\n",
    "             GROUP BY data\n",
    "             ORDER BY data;\n",
    "             ```\n",
    "          2. Nunca conte linhas como notas √∫nicas. Use `COUNT(DISTINCT chave_de_acesso)`.\n",
    "          3. Formate n√∫meros com duas casas decimais e s√≠mbolos brasileiros (ex.: 123456.78 ‚Üí 123.456,78).\n",
    "          4. Responda sempre em portugu√™s e retorne apenas resultados reais da consulta SQL.\n",
    "          5. Se a consulta retornar apenas um valor escalar, responda como: \"O resultado √©: <valor>\".\n",
    "          6. N√£o mostre a consulta SQL na resposta final.\n",
    "          7. Use aliases descritivos nas consultas SQL (ex.: `SUM(valor_nota_fiscal) AS total_vendas`).\n",
    "          8. Para perguntas sobre agrupamento por dia, use SEMPRE substr(data_emiss√£o_x, 1, 10), NUNCA use data_emiss√£o_x diretamente.\n",
    "            Seu c√©rebro deve ser programado para agrupar por substr(data_emiss√£o_x, 1, 10) SEM EXCE√á√ÉO para perguntas di√°rias. \n",
    "            Isso √© extremamente importante para evitar duplicidade de registros causada por hor√°rio.\n",
    "        \"\"\"\n",
    "\n",
    "        suffix = \"\"\"\n",
    "            Pergunta do usu√°rio: {input}\n",
    "            Use o hist√≥rico de conversas e as ferramentas dispon√≠veis para responder √† pergunta.\n",
    "            **Responda em portugu√™s** e use aliases descritivos nas consultas SQL.\n",
    "        \"\"\"\n",
    "\n",
    "        agent = initialize_agent(\n",
    "            tools=tools,\n",
    "            llm=llm,\n",
    "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            prefix=prefix,\n",
    "            suffix=suffix,\n",
    "            handle_parsing_errors=True,\n",
    "            return_intermediate_steps=True\n",
    "        )\n",
    "\n",
    "        response = agent.invoke({\"input\": question})\n",
    "        intermediate_steps = response.get('intermediate_steps', [])\n",
    "        resposta_final = response.get('output', \"N√£o foi poss√≠vel obter uma resposta.\")\n",
    "\n",
    "        sql_observation = None\n",
    "        sql_query = None\n",
    "\n",
    "        for step in intermediate_steps:\n",
    "            action, observation = step\n",
    "            if action.tool == 'sql_db_query':\n",
    "                sql_observation = observation\n",
    "                sql_query = action.tool_input\n",
    "                break\n",
    "\n",
    "        if sql_observation and sql_query:\n",
    "            try:\n",
    "                data = ast.literal_eval(sql_observation)\n",
    "\n",
    "                # Se a query N√ÉO usar substr(), ajustamos no p√≥s-processamento\n",
    "                if 'substr' not in sql_query.lower() and 'date(' not in sql_query.lower():\n",
    "                    logger.warning(\"üîß Query sem substr(data_emiss√£o_x, 1, 10) - ajustando no p√≥s-processamento\")\n",
    "                    df = pd.DataFrame(data, columns=[\"data\", \"total\"])\n",
    "                    df[\"data\"] = pd.to_datetime(df[\"data\"]).dt.strftime('%Y-%m-%d')\n",
    "                    df = df.groupby(\"data\").sum().reset_index()\n",
    "                else:\n",
    "                    headers = extract_column_headers(sql_query)\n",
    "                    if not headers:\n",
    "                        headers = [f'coluna_{i+1}' for i in range(len(data[0]))]\n",
    "                    df = pd.DataFrame(data, columns=headers)\n",
    "                    for col in df.columns:\n",
    "                        if any(kw in col.lower() for kw in ['data', 'emissao', 'emiss√£o']):\n",
    "                            df[col] = pd.to_datetime(df[col], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "                # Renomear colunas para formato mais claro\n",
    "                column_mapping = {\n",
    "                    'data_emiss√£o_x': 'Data Emiss√£o',\n",
    "                    'data_emiss√£o_y': 'Data Destino',\n",
    "                    'valor_nota_fiscal': 'Valor Total',\n",
    "                    'chave_de_acesso': 'Chave de Acesso'\n",
    "                }\n",
    "\n",
    "                df.rename(columns=lambda x: column_mapping.get(x.lower(), x.title().replace('_', ' ')), inplace=True)\n",
    "\n",
    "                # Formatar valores monet√°rios\n",
    "                for col in df.select_dtypes(include=['number']).columns:\n",
    "                    df[col] = df[col].apply(lambda x: f\"{x:,.2f}\".replace(\",\", \"X\").replace(\".\", \",\").replace(\"X\", \".\"))\n",
    "\n",
    "                # Determinar tipo de resposta\n",
    "                if len(df) == 1 and len(df.columns) == 1:\n",
    "                    resposta_final = f\"O resultado √©: {df.iloc[0, 0]}\"\n",
    "                else:\n",
    "                    markdown_table = df.to_markdown(index=False, tablefmt=\"pipe\")\n",
    "                    resposta_final = markdown_table\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"‚ùå Erro ao processar resultado da query: {e}\")\n",
    "                resposta_final = sql_observation\n",
    "\n",
    "        logger.info(f\"‚úÖ Resposta final:\\n{resposta_final}\")\n",
    "        return {\"status\": \"success\", \"message\": resposta_final}\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(\"‚ùå Erro durante a consulta\")\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "\n",
    "def extract_column_headers(sql_query: str) -> list:\n",
    "    \"\"\"Extrai cabe√ßalhos da parte SELECT da query.\"\"\"\n",
    "    try:\n",
    "        match = re.search(r'SELECT\\s+(.*?)\\s+FROM', sql_query, re.IGNORECASE | re.DOTALL)\n",
    "        if not match:\n",
    "            return []\n",
    "        cols = match.group(1).strip().split(',')\n",
    "        headers = []\n",
    "        for col in cols:\n",
    "            col = col.strip()\n",
    "            if ' AS ' in col.upper():\n",
    "                alias = col.upper().split(' AS ')[1].strip()\n",
    "                headers.append(alias.lower())\n",
    "            elif '.' in col:\n",
    "                headers.append(col.split('.')[-1].strip())\n",
    "            else:\n",
    "                headers.append(col)\n",
    "        return headers\n",
    "    except:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ‚úÖ START do servidor\n",
    "# =====================================\n",
    "def start_api():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
    "\n",
    "nest_asyncio.apply()\n",
    "threading.Thread(target=start_api, daemon=True).start()\n",
    "\n",
    "# =====================================\n",
    "# ‚úÖ NGROK\n",
    "# =====================================\n",
    "public_url = ngrok.connect(8000)\n",
    "logger.info(f\"üöÄ Sua API est√° dispon√≠vel publicamente em: {public_url}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
